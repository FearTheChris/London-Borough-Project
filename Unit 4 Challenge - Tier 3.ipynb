{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tia3MP1SJpgj"
   },
   "source": [
    "# Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete\n",
    "\n",
    "## Objectives\n",
    "Hey! Great job getting through those challenging DataCamp courses. You're learning a lot in a short span of time. \n",
    "\n",
    "In this notebook, you're going to apply the skills you've been learning, bridging the gap between the controlled environment of DataCamp and the *slightly* messier work that data scientists do with actual datasets!\n",
    "\n",
    "Here’s the mystery we’re going to solve: ***which boroughs of London have seen the greatest increase in housing prices, on average, over the last two decades?***\n",
    "\n",
    "\n",
    "A borough is just a fancy word for district. You may be familiar with the five boroughs of New York… well, there are 32 boroughs within Greater London [(here's some info for the curious)](https://en.wikipedia.org/wiki/London_boroughs). Some of them are more desirable areas to live in, and the data will reflect that with a greater rise in housing prices.\n",
    "\n",
    "***This is the Tier 3 notebook, which means it's not filled in at all: we'll just give you the skeleton of a project, the brief and the data. It's up to you to play around with it and see what you can find out! Good luck! If you struggle, feel free to look at easier tiers for help; but try to dip in and out of them, as the more independent work you do, the better it is for your learning!***\n",
    "\n",
    "This challenge will make use of only what you learned in the following DataCamp courses: \n",
    "- Prework courses (Introduction to Python for Data Science, Intermediate Python for Data Science)\n",
    "- Data Types for Data Science\n",
    "- Python Data Science Toolbox (Part One) \n",
    "- pandas Foundations\n",
    "- Manipulating DataFrames with pandas\n",
    "- Merging DataFrames with pandas\n",
    "\n",
    "Of the tools, techniques and concepts in the above DataCamp courses, this challenge should require the application of the following: \n",
    "- **pandas**\n",
    "    - **data ingestion and inspection** (pandas Foundations, Module One) \n",
    "    - **exploratory data analysis** (pandas Foundations, Module Two)\n",
    "    - **tidying and cleaning** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **transforming DataFrames** (Manipulating DataFrames with pandas, Module One)\n",
    "    - **subsetting DataFrames with lists** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **filtering DataFrames** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **grouping data** (Manipulating DataFrames with pandas, Module Four) \n",
    "    - **melting data** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **advanced indexing** (Manipulating DataFrames with pandas, Module Four) \n",
    "- **matplotlib** (Intermediate Python for Data Science, Module One)\n",
    "- **fundamental data types** (Data Types for Data Science, Module One) \n",
    "- **dictionaries** (Intermediate Python for Data Science, Module Two)\n",
    "- **handling dates and times** (Data Types for Data Science, Module Four)\n",
    "- **function definition** (Python Data Science Toolbox - Part One, Module One)\n",
    "- **default arguments, variable length, and scope** (Python Data Science Toolbox - Part One, Module Two) \n",
    "- **lambda functions and error handling** (Python Data Science Toolbox - Part One, Module Four) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ipgd2nV8Jpgl"
   },
   "source": [
    "## The Data Science Pipeline\n",
    "\n",
    "This is Tier Three, so we'll get you started. But after that, it's all in your hands! When you feel done with your investigations, look back over what you've accomplished, and prepare a quick presentation of your findings for the next mentor meeting. \n",
    "\n",
    "Data Science is magical. In this case study, you'll get to apply some complex machine learning algorithms. But as  [David Spiegelhalter](https://www.youtube.com/watch?v=oUs1uvsz0Ok) reminds us, there is no substitute for simply **taking a really, really good look at the data.** Sometimes, this is all we need to answer our question.\n",
    "\n",
    "Data Science projects generally adhere to the four stages of Data Science Pipeline:\n",
    "1. Sourcing and loading \n",
    "2. Cleaning, transforming, and visualizing \n",
    "3. Modeling \n",
    "4. Evaluating and concluding \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zswDqbefJpgm"
   },
   "source": [
    "### 1. Sourcing and Loading \n",
    "\n",
    "Any Data Science project kicks off by importing  ***pandas***. The documentation of this wonderful library can be found [here](https://pandas.pydata.org/). As you've seen, pandas is conveniently connected to the [Numpy](http://www.numpy.org/) and [Matplotlib](https://matplotlib.org/) libraries. \n",
    "\n",
    "***Hint:*** This part of the data science pipeline will test those skills you acquired in the pandas Foundations course, Module One. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEau5nEvJpgm"
   },
   "source": [
    "#### 1.1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Bt_Q_oPJpgn"
   },
   "outputs": [],
   "source": [
    "# Let's import the pandas, numpy libraries as pd, and np respectively. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the pyplot collection of functions from matplotlib, as plt \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koUrawxsJpgq"
   },
   "source": [
    "#### 1.2.  Loading the data\n",
    "Your data comes from the [London Datastore](https://data.london.gov.uk/): a free, open-source data-sharing portal for London-oriented datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AiLiD4v3Jpgr"
   },
   "outputs": [],
   "source": [
    "# First, make a variable called url_LondonHousePrices, and assign it the following link, enclosed in quotation-marks as a string:\n",
    "# https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\n",
    "\n",
    "url_LondonHousePrices = \"https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\"\n",
    "\n",
    "# The dataset we're interested in contains the Average prices of the houses, and is actually on a particular sheet of the Excel file. \n",
    "# As a result, we need to specify the sheet name in the read_excel() method.\n",
    "# Put this data into a variable called properties.  \n",
    "prop = pd.read_excel(url_LondonHousePrices, sheet_name='Average price', index_col= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "POukEJXgJpgu"
   },
   "source": [
    "### 2. Cleaning, transforming, and visualizing\n",
    "This second stage is arguably the most important part of any Data Science project. The first thing to do is take a proper look at the data. Cleaning forms the majority of this stage, and can be done both before or after Transformation.\n",
    "\n",
    "The end goal of data cleaning is to have tidy data. When data is tidy: \n",
    "\n",
    "1. Each variable has a column.\n",
    "2. Each observation forms a row.\n",
    "\n",
    "Keep the end goal in mind as you move through this process, every step will take you closer. \n",
    "\n",
    "\n",
    "\n",
    "***Hint:*** This part of the data science pipeline should test those skills you acquired in: \n",
    "- Intermediate Python for data science, all modules.\n",
    "- pandas Foundations, all modules. \n",
    "- Manipulating DataFrames with pandas, all modules.\n",
    "- Data Types for Data Science, Module Four.\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Te0Q548tnzZa"
   },
   "source": [
    "**2.1. Exploring your data** \n",
    "\n",
    "Think about your pandas functions for checking out a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rxirxw_qoAJa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prop = prop.drop(labels=[\"Unnamed: 47\",\"YORKS & THE HUMBER\", \"Unnamed: 37\",\"Unnamed: 34\",\"City of London\",\"England\",\"Inner London\",\"Outer London\",\"NORTH EAST\",\"NORTH WEST\",\"EAST MIDLANDS\",\"WEST MIDLANDS\",\"EAST OF ENGLAND\",\"LONDON\",\"SOUTH EAST\",\"SOUTH WEST\"],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE9Sqt9-oAta"
   },
   "source": [
    "**2.2. Cleaning the data**\n",
    "\n",
    "You might find you need to transpose your dataframe, check out what its row indexes are, and reset the index. You  also might find you need to assign the values of the first row to your column headings  . (Hint: recall the .columns feature of DataFrames, as well as the iloc[] method).\n",
    "\n",
    "Don't be afraid to use StackOverflow for help  with this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdAu1A3YoH_r"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>London Borough</th>\n",
       "      <th>ID</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2022-03-01 00:00:00</th>\n",
       "      <th>2022-04-01 00:00:00</th>\n",
       "      <th>2022-05-01 00:00:00</th>\n",
       "      <th>2022-06-01 00:00:00</th>\n",
       "      <th>2022-07-01 00:00:00</th>\n",
       "      <th>2022-08-01 00:00:00</th>\n",
       "      <th>2022-09-01 00:00:00</th>\n",
       "      <th>2022-10-01 00:00:00</th>\n",
       "      <th>2022-11-01 00:00:00</th>\n",
       "      <th>2022-12-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2266</td>\n",
       "      <td>51085.77983</td>\n",
       "      <td>51268.96956</td>\n",
       "      <td>53133.50526</td>\n",
       "      <td>53042.24852</td>\n",
       "      <td>53700.34831</td>\n",
       "      <td>52113.12157</td>\n",
       "      <td>52232.19868</td>\n",
       "      <td>...</td>\n",
       "      <td>337639.17828</td>\n",
       "      <td>333921.39153</td>\n",
       "      <td>337201.79953</td>\n",
       "      <td>345873.99616</td>\n",
       "      <td>349371.12076</td>\n",
       "      <td>350239.35981</td>\n",
       "      <td>349653.85502</td>\n",
       "      <td>355290.62346</td>\n",
       "      <td>359495.10689</td>\n",
       "      <td>362054.07567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.51832</td>\n",
       "      <td>93190.16963</td>\n",
       "      <td>92247.52435</td>\n",
       "      <td>90762.87492</td>\n",
       "      <td>90258.00033</td>\n",
       "      <td>90107.23471</td>\n",
       "      <td>91441.24768</td>\n",
       "      <td>92361.31512</td>\n",
       "      <td>...</td>\n",
       "      <td>573655.09452</td>\n",
       "      <td>581811.27928</td>\n",
       "      <td>587188.06846</td>\n",
       "      <td>592754.89104</td>\n",
       "      <td>594041.83267</td>\n",
       "      <td>601931.6599</td>\n",
       "      <td>605424.18481</td>\n",
       "      <td>597777.32861</td>\n",
       "      <td>587967.70766</td>\n",
       "      <td>595486.30411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.09036</td>\n",
       "      <td>64787.92069</td>\n",
       "      <td>64367.49344</td>\n",
       "      <td>64277.66881</td>\n",
       "      <td>63997.13588</td>\n",
       "      <td>64252.32335</td>\n",
       "      <td>63722.70055</td>\n",
       "      <td>64432.60005</td>\n",
       "      <td>...</td>\n",
       "      <td>386972.05239</td>\n",
       "      <td>385161.3244</td>\n",
       "      <td>386673.4299</td>\n",
       "      <td>391819.71089</td>\n",
       "      <td>396385.99016</td>\n",
       "      <td>402667.50443</td>\n",
       "      <td>403468.56545</td>\n",
       "      <td>409719.69933</td>\n",
       "      <td>410407.63764</td>\n",
       "      <td>416059.80994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>71306.56698</td>\n",
       "      <td>72022.26197</td>\n",
       "      <td>72015.76274</td>\n",
       "      <td>72965.63094</td>\n",
       "      <td>73704.04743</td>\n",
       "      <td>74310.48167</td>\n",
       "      <td>74127.03788</td>\n",
       "      <td>73547.0411</td>\n",
       "      <td>...</td>\n",
       "      <td>508372.8301</td>\n",
       "      <td>522338.64309</td>\n",
       "      <td>533942.03626</td>\n",
       "      <td>536486.89116</td>\n",
       "      <td>552316.75952</td>\n",
       "      <td>562407.51963</td>\n",
       "      <td>584927.5386</td>\n",
       "      <td>578010.59307</td>\n",
       "      <td>572262.24808</td>\n",
       "      <td>566794.73925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bromley</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>81671.47692</td>\n",
       "      <td>81657.55944</td>\n",
       "      <td>81449.31143</td>\n",
       "      <td>81124.41227</td>\n",
       "      <td>81542.61561</td>\n",
       "      <td>82382.83435</td>\n",
       "      <td>82898.52264</td>\n",
       "      <td>82054.37156</td>\n",
       "      <td>...</td>\n",
       "      <td>480229.23775</td>\n",
       "      <td>486445.91707</td>\n",
       "      <td>491230.70286</td>\n",
       "      <td>502416.10181</td>\n",
       "      <td>505704.35059</td>\n",
       "      <td>513498.76677</td>\n",
       "      <td>515462.53348</td>\n",
       "      <td>522979.73425</td>\n",
       "      <td>523810.59406</td>\n",
       "      <td>523364.68872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 338 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0      London Borough         ID 1995-01-01 00:00:00 1995-02-01 00:00:00  \\\n",
       "1  Barking & Dagenham  E09000002          50460.2266         51085.77983   \n",
       "2              Barnet  E09000003         93284.51832         93190.16963   \n",
       "3              Bexley  E09000004         64958.09036         64787.92069   \n",
       "4               Brent  E09000005         71306.56698         72022.26197   \n",
       "5             Bromley  E09000006         81671.47692         81657.55944   \n",
       "\n",
       "0 1995-03-01 00:00:00 1995-04-01 00:00:00 1995-05-01 00:00:00  \\\n",
       "1         51268.96956         53133.50526         53042.24852   \n",
       "2         92247.52435         90762.87492         90258.00033   \n",
       "3         64367.49344         64277.66881         63997.13588   \n",
       "4         72015.76274         72965.63094         73704.04743   \n",
       "5         81449.31143         81124.41227         81542.61561   \n",
       "\n",
       "0 1995-06-01 00:00:00 1995-07-01 00:00:00 1995-08-01 00:00:00  ...  \\\n",
       "1         53700.34831         52113.12157         52232.19868  ...   \n",
       "2         90107.23471         91441.24768         92361.31512  ...   \n",
       "3         64252.32335         63722.70055         64432.60005  ...   \n",
       "4         74310.48167         74127.03788          73547.0411  ...   \n",
       "5         82382.83435         82898.52264         82054.37156  ...   \n",
       "\n",
       "0 2022-03-01 00:00:00 2022-04-01 00:00:00 2022-05-01 00:00:00  \\\n",
       "1        337639.17828        333921.39153        337201.79953   \n",
       "2        573655.09452        581811.27928        587188.06846   \n",
       "3        386972.05239         385161.3244         386673.4299   \n",
       "4         508372.8301        522338.64309        533942.03626   \n",
       "5        480229.23775        486445.91707        491230.70286   \n",
       "\n",
       "0 2022-06-01 00:00:00 2022-07-01 00:00:00 2022-08-01 00:00:00  \\\n",
       "1        345873.99616        349371.12076        350239.35981   \n",
       "2        592754.89104        594041.83267         601931.6599   \n",
       "3        391819.71089        396385.99016        402667.50443   \n",
       "4        536486.89116        552316.75952        562407.51963   \n",
       "5        502416.10181        505704.35059        513498.76677   \n",
       "\n",
       "0 2022-09-01 00:00:00 2022-10-01 00:00:00 2022-11-01 00:00:00  \\\n",
       "1        349653.85502        355290.62346        359495.10689   \n",
       "2        605424.18481        597777.32861        587967.70766   \n",
       "3        403468.56545        409719.69933        410407.63764   \n",
       "4         584927.5386        578010.59307        572262.24808   \n",
       "5        515462.53348        522979.73425        523810.59406   \n",
       "\n",
       "0 2022-12-01 00:00:00  \n",
       "1        362054.07567  \n",
       "2        595486.30411  \n",
       "3        416059.80994  \n",
       "4        566794.73925  \n",
       "5        523364.68872  \n",
       "\n",
       "[5 rows x 338 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_t = prop.transpose()\n",
    "prop_t = prop_t.reset_index()\n",
    "col1 = prop_t.columns\n",
    "row_head = prop_t.iloc[0]\n",
    "prop_t.columns = prop_t.iloc[0]\n",
    "prop_t = prop_t.drop(labels=0, axis=0)\n",
    "prop_t = prop_t.rename(columns={\"Unnamed: 0\":\"London Borough\" , pd.NaT: 'ID'})\n",
    "prop_t.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1uLbJAsoIjK"
   },
   "source": [
    "**2.3. Cleaning the data (part 2)**\n",
    "\n",
    "You might we have to **rename** a couple columns. How do you do this? The clue's pretty bold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKkmn1AnoVZS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>London Borough</th>\n",
       "      <th>ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Average Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>131709.3326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>236505.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>153739.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>207775.1926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>Bromley</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>204090.9091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>Camden</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>328996.2959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>Croydon</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>174796.3015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>Ealing</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>215626.1416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>Enfield</td>\n",
       "      <td>E09000010</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>180595.2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>Greenwich</td>\n",
       "      <td>E09000011</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>158655.0274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>Hackney</td>\n",
       "      <td>E09000012</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>195298.2814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>Hammersmith &amp; Fulham</td>\n",
       "      <td>E09000013</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>322552.1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>Haringey</td>\n",
       "      <td>E09000014</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>218163.4545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>Harrow</td>\n",
       "      <td>E09000015</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>223334.3877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>Havering</td>\n",
       "      <td>E09000016</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>169085.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>Hillingdon</td>\n",
       "      <td>E09000017</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>190909.0844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>Hounslow</td>\n",
       "      <td>E09000018</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>188839.0226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>Islington</td>\n",
       "      <td>E09000019</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>257882.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>Kensington &amp; Chelsea</td>\n",
       "      <td>E09000020</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>468163.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>Kingston upon Thames</td>\n",
       "      <td>E09000021</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>222346.8239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>E09000022</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>204576.4686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>Lewisham</td>\n",
       "      <td>E09000023</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>160358.7313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>Merton</td>\n",
       "      <td>E09000024</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>213487.8816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>Newham</td>\n",
       "      <td>E09000025</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>157600.9748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>Redbridge</td>\n",
       "      <td>E09000026</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>190454.4267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            London Borough         ID      Month Average Price\n",
       "3040    Barking & Dagenham  E09000002 2002-12-01   131709.3326\n",
       "3041                Barnet  E09000003 2002-12-01    236505.764\n",
       "3042                Bexley  E09000004 2002-12-01    153739.506\n",
       "3043                 Brent  E09000005 2002-12-01   207775.1926\n",
       "3044               Bromley  E09000006 2002-12-01   204090.9091\n",
       "3045                Camden  E09000007 2002-12-01   328996.2959\n",
       "3046               Croydon  E09000008 2002-12-01   174796.3015\n",
       "3047                Ealing  E09000009 2002-12-01   215626.1416\n",
       "3048               Enfield  E09000010 2002-12-01   180595.2024\n",
       "3049             Greenwich  E09000011 2002-12-01   158655.0274\n",
       "3050               Hackney  E09000012 2002-12-01   195298.2814\n",
       "3051  Hammersmith & Fulham  E09000013 2002-12-01   322552.1997\n",
       "3052              Haringey  E09000014 2002-12-01   218163.4545\n",
       "3053                Harrow  E09000015 2002-12-01   223334.3877\n",
       "3054              Havering  E09000016 2002-12-01    169085.628\n",
       "3055            Hillingdon  E09000017 2002-12-01   190909.0844\n",
       "3056              Hounslow  E09000018 2002-12-01   188839.0226\n",
       "3057             Islington  E09000019 2002-12-01   257882.0772\n",
       "3058  Kensington & Chelsea  E09000020 2002-12-01   468163.9931\n",
       "3059  Kingston upon Thames  E09000021 2002-12-01   222346.8239\n",
       "3060               Lambeth  E09000022 2002-12-01   204576.4686\n",
       "3061              Lewisham  E09000023 2002-12-01   160358.7313\n",
       "3062                Merton  E09000024 2002-12-01   213487.8816\n",
       "3063                Newham  E09000025 2002-12-01   157600.9748\n",
       "3064             Redbridge  E09000026 2002-12-01   190454.4267"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_prop = pd.melt(prop_t, id_vars=['London Borough','ID'])\n",
    "clean_prop = clean_prop.rename(columns = {0: 'Month','value': 'Average Price'})\n",
    "prop_date = clean_prop.loc[(clean_prop['Month'] >= '2002-12-01')]\n",
    "prop_date.head(25)\n",
    "\n",
    "\n",
    "\n",
    "#properties_clean = properties_clean.loc[(properties_clean['London Borough'] >= '2002-12-01')]\n",
    "#properties_clean = properties_clean.drop(labels=[\"London Borough\"],axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jy8BzXHmoWEw"
   },
   "source": [
    "**2.4.Transforming the data**\n",
    "\n",
    "Remember what Wes McKinney said about tidy data? \n",
    "\n",
    "You might need to **melt** your DataFrame here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2wM0qLuo2Zt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "London Borough    0\n",
       "ID                0\n",
       "Month             0\n",
       "Average Price     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_date.isnull().sum()\n",
    "\n",
    "#properties_clean[\"Overall Price Change\"] = properties_clean['2022-12-01'] - properties_clean['2002-12-01']\n",
    "#properties_clean['Overall Price Change'] = properties_clean.apply(lambda x: x['2022-12-01'] - x['2002-12-01'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kIsgAo7o3mf"
   },
   "source": [
    "Remember to make sure your column data types are all correct. Average prices, for example, should be floating point numbers... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcR4IHbcpOaq"
   },
   "outputs": [],
   "source": [
    "#for col in properties_clean.columns:\n",
    "    #print(col)\n",
    "#print(properties_clean)\n",
    "#print(properties_clean['2002-12-01 00:00:00'])\n",
    "#properties_clean[\"Percentage Price Change\"] = properties_clean.loc['2022-12-01'] - properties_clean.loc['2002-12-01']\n",
    "#print(prop_find)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knLUXHLypOtw"
   },
   "source": [
    "**2.5. Cleaning the data (part 3)**\n",
    "\n",
    "Do we have an equal number of observations in the ID, Average Price, Month, and London Borough columns? Remember that there are only 32 London Boroughs. How many entries do you have in that column? \n",
    "\n",
    "Check out the contents of the London Borough column, and if you find null values, get rid of them however you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnvTW5a3p0fC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_58872\\1277216754.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prop_date['Year'] = prop_date['Month'].apply(lambda t: t.year)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>London Borough</th>\n",
       "      <th>ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Average Price</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10732</th>\n",
       "      <td>Haringey</td>\n",
       "      <td>E09000014</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>600910.36651</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10733</th>\n",
       "      <td>Harrow</td>\n",
       "      <td>E09000015</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>542277.05953</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10734</th>\n",
       "      <td>Havering</td>\n",
       "      <td>E09000016</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>442906.34107</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10735</th>\n",
       "      <td>Hillingdon</td>\n",
       "      <td>E09000017</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>475198.34586</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10736</th>\n",
       "      <td>Hounslow</td>\n",
       "      <td>E09000018</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>456554.68425</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10737</th>\n",
       "      <td>Islington</td>\n",
       "      <td>E09000019</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>683287.81858</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10738</th>\n",
       "      <td>Kensington &amp; Chelsea</td>\n",
       "      <td>E09000020</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>1278176.3339</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10739</th>\n",
       "      <td>Kingston upon Thames</td>\n",
       "      <td>E09000021</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>570307.20416</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10740</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>E09000022</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>553849.59378</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10741</th>\n",
       "      <td>Lewisham</td>\n",
       "      <td>E09000023</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>470100.13421</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10742</th>\n",
       "      <td>Merton</td>\n",
       "      <td>E09000024</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>594929.83236</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10743</th>\n",
       "      <td>Newham</td>\n",
       "      <td>E09000025</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>431657.42753</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10744</th>\n",
       "      <td>Redbridge</td>\n",
       "      <td>E09000026</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>487456.65597</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10745</th>\n",
       "      <td>Richmond upon Thames</td>\n",
       "      <td>E09000027</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>742060.80162</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10746</th>\n",
       "      <td>Southwark</td>\n",
       "      <td>E09000028</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>554637.20676</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10747</th>\n",
       "      <td>Sutton</td>\n",
       "      <td>E09000029</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>450999.6808</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10748</th>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>E09000030</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>520524.72039</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10749</th>\n",
       "      <td>Waltham Forest</td>\n",
       "      <td>E09000031</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>510178.70953</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10750</th>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>E09000032</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>657123.47553</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10751</th>\n",
       "      <td>Westminster</td>\n",
       "      <td>E09000033</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>910286.63571</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             London Borough         ID      Month Average Price  Year\n",
       "10732              Haringey  E09000014 2022-12-01  600910.36651  2022\n",
       "10733                Harrow  E09000015 2022-12-01  542277.05953  2022\n",
       "10734              Havering  E09000016 2022-12-01  442906.34107  2022\n",
       "10735            Hillingdon  E09000017 2022-12-01  475198.34586  2022\n",
       "10736              Hounslow  E09000018 2022-12-01  456554.68425  2022\n",
       "10737             Islington  E09000019 2022-12-01  683287.81858  2022\n",
       "10738  Kensington & Chelsea  E09000020 2022-12-01  1278176.3339  2022\n",
       "10739  Kingston upon Thames  E09000021 2022-12-01  570307.20416  2022\n",
       "10740               Lambeth  E09000022 2022-12-01  553849.59378  2022\n",
       "10741              Lewisham  E09000023 2022-12-01  470100.13421  2022\n",
       "10742                Merton  E09000024 2022-12-01  594929.83236  2022\n",
       "10743                Newham  E09000025 2022-12-01  431657.42753  2022\n",
       "10744             Redbridge  E09000026 2022-12-01  487456.65597  2022\n",
       "10745  Richmond upon Thames  E09000027 2022-12-01  742060.80162  2022\n",
       "10746             Southwark  E09000028 2022-12-01  554637.20676  2022\n",
       "10747                Sutton  E09000029 2022-12-01   450999.6808  2022\n",
       "10748         Tower Hamlets  E09000030 2022-12-01  520524.72039  2022\n",
       "10749        Waltham Forest  E09000031 2022-12-01  510178.70953  2022\n",
       "10750            Wandsworth  E09000032 2022-12-01  657123.47553  2022\n",
       "10751           Westminster  E09000033 2022-12-01  910286.63571  2022"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_date['Year'] = prop_date['Month'].apply(lambda t: t.year)\n",
    "prop_date.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGEx6mJsp6dG"
   },
   "source": [
    "**2.6. Visualizing the data**\n",
    "\n",
    "To visualize the data, why not subset on a particular London Borough? Maybe do a line plot of Month against Average Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAg5pT9cqHAR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London Borough            Westminster\n",
      "Year                             2022\n",
      "Month             2022-06-16 12:00:00\n",
      "Average Price          1428917.607883\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_58872\\4279922453.py:1: FutureWarning: Dropping invalid columns in DataFrameGroupBy.mean is deprecated. In a future version, a TypeError will be raised. Before calling .mean, select only columns which should be valid for the function.\n",
      "  prop_slice = prop_date.groupby(by=['London Borough', 'Year']).mean()\n"
     ]
    }
   ],
   "source": [
    "prop_slice = prop_date.groupby(by=['London Borough', 'Year']).mean()\n",
    "prop_slice = prop_slice.reset_index()\n",
    "maxValues = prop_slice.max()\n",
    "print(maxValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWTPqSJeqHnC"
   },
   "source": [
    "To limit the number of data points you have, you might want to extract the year from every month value your *Month* column. \n",
    "\n",
    "To this end, you *could* apply a ***lambda function***. Your logic could work as follows:\n",
    "1. look through the `Month` column\n",
    "2. extract the year from each individual value in that column \n",
    "3. store that corresponding year as separate column. \n",
    "\n",
    "Whether you go ahead with this is up to you. Just so long as you answer our initial brief: which boroughs of London have seen the greatest house price increase, on average, over the past two decades? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0DF92cyqnu8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Barking & Dagenham': [2.6264181811099694], 'Barnet': [2.489931778399842], 'Bexley': [2.5763756101018047], 'Brent': [2.6247304329575356], 'Bromley': [2.4571777181622636], 'Camden': [2.6031162269715793], 'Croydon': [2.39782294602307], 'Ealing': [2.4507610304713014], 'Enfield': [2.490941198308377], 'Greenwich': [2.703816847664755], 'Hackney': [3.2295473778381476], 'Hammersmith & Fulham': [2.376093382271132], 'Haringey': [2.7366387442043676], 'Harrow': [2.3316635318434065], 'Havering': [2.4960999563093167], 'Hillingdon': [2.396890480520964], 'Hounslow': [2.3508212853927017], 'Islington': [2.767419994077433], 'Kensington & Chelsea': [3.052173231908751], 'Kingston upon Thames': [2.452906678098645], 'Lambeth': [2.67685680718038], 'Lewisham': [2.84267387749656], 'Merton': [2.6785554680636268], 'Newham': [2.611272448074985], 'Redbridge': [2.497776612066709], 'Richmond upon Thames': [2.5989199697528074], 'Southwark': [2.8461344558818986], 'Sutton': [2.43471628893239], 'Tower Hamlets': [2.3165761053862934], 'Waltham Forest': [3.0081823860362045], 'Wandsworth': [2.6499894333341105], 'Westminster': [2.680097158933206]}\n"
     ]
    }
   ],
   "source": [
    "def create_price_ratio(d):\n",
    "    y2002 = float(d['Average Price'][d['Year']==2002])\n",
    "    y2022 = float(d['Average Price'][d['Year']==2022])\n",
    "    ratio = [y2022/y2002]\n",
    "    return ratio\n",
    "create_price_ratio(prop_slice[prop_slice['London Borough']=='Barking & Dagenham'])\n",
    "final = {}\n",
    "for bor in prop_slice['London Borough'].unique():\n",
    "    # Let's make our parameter to our create_price_ratio function: i.e., we subset dfg on 'London_Borough' == b. \n",
    "    borough = prop_slice[prop_slice['London Borough'] == bor]\n",
    "    # Make a new entry in the final dictionary whose value's the result of calling create_price_ratio with the argument: borough\n",
    "    final[bor] = create_price_ratio(borough)\n",
    "print(final) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2knuTxAEqoJ4"
   },
   "source": [
    "**3. Modeling**\n",
    "\n",
    "Consider creating a function that will calculate a ratio of house prices, comparing the price of a house in 2018 to the price in 1998.\n",
    "\n",
    "Consider calling this function create_price_ratio.\n",
    "\n",
    "You'd want this function to:\n",
    "1. Take a filter of dfg, specifically where this filter constrains the London_Borough, as an argument. For example, one admissible argument should be: dfg[dfg['London_Borough']=='Camden'].\n",
    "2. Get the Average Price for that Borough, for the years 1998 and 2018.\n",
    "4. Calculate the ratio of the Average Price for 1998 divided by the Average Price for 2018.\n",
    "5. Return that ratio.\n",
    "\n",
    "Once you've written this function, you ultimately want to use it to iterate through all the unique London_Boroughs and work out the ratio capturing the difference of house prices between 1998 and 2018.\n",
    "\n",
    "Bear in mind: you don't have to write a function like this if you don't want to. If you can solve the brief otherwise, then great! \n",
    "\n",
    "***Hint***: This section should test the skills you acquired in:\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKTyr437UgDa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Borough      2022\n",
      "10               Hackney  3.229547\n",
      "18  Kensington & Chelsea  3.052173\n",
      "29        Waltham Forest  3.008182\n",
      "26             Southwark  2.846134\n",
      "21              Lewisham  2.842674\n",
      "17             Islington  2.767420\n",
      "12              Haringey  2.736639\n",
      "9              Greenwich  2.703817\n",
      "31           Westminster  2.680097\n",
      "22                Merton  2.678555\n",
      "20               Lambeth  2.676857\n",
      "30            Wandsworth  2.649989\n",
      "0     Barking & Dagenham  2.626418\n",
      "3                  Brent  2.624730\n",
      "23                Newham  2.611272\n",
      "5                 Camden  2.603116\n",
      "25  Richmond upon Thames  2.598920\n",
      "2                 Bexley  2.576376\n",
      "24             Redbridge  2.497777\n",
      "14              Havering  2.496100\n",
      "8                Enfield  2.490941\n",
      "1                 Barnet  2.489932\n",
      "4                Bromley  2.457178\n",
      "19  Kingston upon Thames  2.452907\n",
      "7                 Ealing  2.450761\n",
      "27                Sutton  2.434716\n",
      "6                Croydon  2.397823\n",
      "15            Hillingdon  2.396890\n",
      "11  Hammersmith & Fulham  2.376093\n",
      "16              Hounslow  2.350821\n",
      "13                Harrow  2.331664\n",
      "28         Tower Hamlets  2.316576\n"
     ]
    }
   ],
   "source": [
    "increase_per = pd.DataFrame(final)\n",
    "increase_per_T = increase_per.T\n",
    "increase_per_T = increase_per_T.reset_index()\n",
    "increase_per_T.rename(columns={'index':\"Borough\", 0:'2022'}, inplace=True)\n",
    "increase_per_T.head()\n",
    "biggest_c = increase_per_T.sort_values(by='2022',ascending = False).head(35)\n",
    "print(biggest_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzYUI7FxJpgv"
   },
   "source": [
    "### 4. Conclusion\n",
    "What can you conclude? Type out your conclusion below. \n",
    "\n",
    "Look back at your notebook. Think about how you might summarize what you have done, and prepare a quick presentation on it to your mentor at your next meeting. \n",
    "\n",
    "We hope you enjoyed this practical project. It should have consolidated your data hygiene and pandas skills by looking at a real-world problem involving just the kind of dataset you might encounter as a budding data scientist. Congratulations, and looking forward to seeing you at the next step in the course! "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
